{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 说明：\n",
    "\n",
    "* 本代码是用yolov3或yolo-tiny来识别害虫；\n",
    "* 数据集是虫子,格式是xml;\n",
    "* 代码中数据集的解析过程是先把xml转换成了txt \n",
    "\n",
    "* 可能报错的地方：GPU配置不对应：可能需要在后面代码中修改use_GPU，能用/不能用GPU对应True/False.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解压数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压bugs data\n",
    "!cd data/data7085/ && unzip -qo train.zip && unzip -q test.zip && unzip -q val.zip \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解析xml\n",
    "\n",
    "* 本次的数据集是用labelImg标注的，所以生成的是XML格式；\n",
    "* xml文件一般不能直接读取，一般要先解析，转换成“X + label”这种形式（比如txt等），才能送进网络来训练；\n",
    "* 运行下面代码之后，就生成了train.txt、test.txt、label_list.txt 、label_list 四个文件；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按要求处理数据\n",
    "#!/usr/bin/evn python \n",
    "#coding:utf-8 \n",
    "import os\n",
    "\n",
    "try: \n",
    "  import xml.etree.cElementTree as ET \n",
    "except ImportError: \n",
    "  import xml.etree.ElementTree as ET \n",
    "import sys \n",
    "\n",
    "# 分别制作 train  test  val ， 一共要跑三次哦\n",
    "for set_ in ['train', 'test', 'val']:\n",
    "    xml_ROOT = 'data/data7085/{}/annotations/xmls'.format(set_)\n",
    "    jpg_ROOT = 'data/data7085/{}/images'.format(set_)\n",
    "    out_txt_path = 'data/data7085/{}.txt'.format(set_)\n",
    "    \n",
    "    print(set_)\n",
    "    \n",
    "    xml_list = os.listdir(xml_ROOT)  #其中包含所有待计算的文件名\n",
    "    \n",
    "    if os.path.exists(out_txt_path):\n",
    "        os.remove(out_txt_path)\n",
    "    \n",
    "    txt = open(out_txt_path, 'w')\n",
    "    \n",
    "    for xml_n in xml_list:\n",
    "        xml_path = os.path.join(xml_ROOT, xml_n)\n",
    "        tree = ET.parse(xml_path)     #打开xml文档 \n",
    "        root = tree.getroot()         #获得root节点  \n",
    "        # print (\"*\"*10)\n",
    "        filename = root.find('filename').text\n",
    "        filename = os.path.join(jpg_ROOT, filename)\n",
    "        # print (filename)\n",
    "    \n",
    "        all_box_str = filename+'\\t'\n",
    "        box_count = 0\n",
    "        for object in root.findall('object'): #找到root节点下的所有object节点 \n",
    "            name = object.find('name').text   #子节点下节点name的值 \n",
    "            if name!= 'Leconte':\n",
    "                continue\n",
    "            \n",
    "            box_count += 1\n",
    "            bndbox = object.find('bndbox')      #子节点下属性bndbox的值 \n",
    "            xmin = float(bndbox.find('xmin').text)\n",
    "            ymin = float(bndbox.find('ymin').text)\n",
    "            xmax = float(bndbox.find('xmax').text)\n",
    "            ymax = float(bndbox.find('ymax').text)\n",
    "            \n",
    "            # 图片路径\\t\t{\"value\":\"bolt\",\"coordinate\":[[769.459,241.819],[947.546,506.167]]}\\t{...}... 注意，每个字段值之间用\\t分割\n",
    "            box_str = '{{\\\"value\\\":\\\"Leconte\\\",\\\"coordinate\\\":[[{:.3f},{:.3f}],[{:.3f},{:.3f}]]}}\\t'.\\\n",
    "                                                            format(xmin,  ymin,  xmax, ymax)\n",
    "            all_box_str += box_str\n",
    "            pass\n",
    "        \n",
    "        if box_count==0:\n",
    "            continue\n",
    "        \n",
    "        all_box_str += '\\n'\n",
    "        # print(all_box_str)\n",
    "        txt.write(all_box_str)\n",
    "    txt.close()\n",
    "    print ('{}.txt is ok '.format(set_))\n",
    "\n",
    "txt = open('data/data7085/label_list', 'w')\n",
    "txt.write('Leconte')\n",
    "txt.close()\n",
    "print ('label_list is ok')\n",
    "txt = open('data/data7085/label_list.txt', 'w')\n",
    "txt.write('0\\tLeconte')\n",
    "txt.close()\n",
    "print ('label_list.txt is ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特别提醒：\n",
    "* 运行完上面代码之后，要重启一下Kernel，然后再运行下面往后的所有代码，这样不会报错。\n",
    "\n",
    "* 如果，偶尔出现cant call...once之类的问题，刷新下页面，重启Kernel。问题可以解决。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 设置Yolov3模型的配置项\n",
    "* 设置训练Yolov3模型的配置项，此代码没有预训练模型。可以选择是否启用tiny版本，tiny版本体积小，适合部署在移动设备。\n",
    "\n",
    "* 如果不熟悉yolov3模型，请不要随便更改图片的尺寸和anchors的尺寸，两者相互关联。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "训练常基于dark-net的YOLOv3网络，目标检测\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import time\n",
    "import six\n",
    "import math\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import logging\n",
    "import xml.etree.ElementTree\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from paddle.fluid.regularizer import L2Decay\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "\n",
    "logger = None\n",
    "train_parameters = {\n",
    "    \"data_dir\": \"data/data7085/\",\n",
    "    \"file_list\": \"train.txt\",\n",
    "    \"class_dim\": -1,\n",
    "    \"label_dict\": {},\n",
    "    \"image_count\": -1,\n",
    "    \"continue_train\": False,     # 是否加载前一次的训练参数，接着训练\n",
    "    \"pretrained\": False,\n",
    "    \"pretrained_model_dir\": \"./pretrained-model\",\n",
    "    \"save_model_dir\": \"./yolo-model\",\n",
    "    \"model_prefix\": \"yolo-v3\",\n",
    "    \"use_tiny\": True,          # 是否使用 裁剪 tiny 模型\n",
    "    \"max_box_num\": 20,          # 一幅图上最多有多少个目标\n",
    "    \"num_epochs\": 120,\n",
    "    \"train_batch_size\": 5,      # 对于完整 yolov3，每一批的训练样本不能太多，内存会炸掉\n",
    "    \"use_gpu\":False,\n",
    "    \"yolo_cfg\": {\n",
    "        \"input_size\": [3, 608, 608],\n",
    "        \"anchors\": [10, 13,  16, 30,  33, 23,  30, 61,  62, 45,  59, 119,  116, 90,  156, 198,  373, 326],\n",
    "        \"anchor_mask\": [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"yolo_tiny_cfg\": {\n",
    "        \"input_size\": [3, 256, 256],\n",
    "        \"anchors\": [6, 8, 13, 15, 22, 34, 48, 50, 81, 100, 205, 191],\n",
    "        \"anchor_mask\": [[3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"ignore_thresh\": 0.7,\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],\n",
    "    \"mode\": \"train\",\n",
    "    \"multi_data_reader_count\": 4,\n",
    "    \"apply_distort\": True,\n",
    "    \"valid_thresh\": 0.01,\n",
    "    \"nms_thresh\": 0.45,\n",
    "    \"image_distort_strategy\": {\n",
    "        \"expand_prob\": 0.5,\n",
    "        \"expand_max_ratio\": 4,\n",
    "        \"hue_prob\": 0.5,\n",
    "        \"hue_delta\": 18,\n",
    "        \"contrast_prob\": 0.5,\n",
    "        \"contrast_delta\": 0.5,\n",
    "        \"saturation_prob\": 0.5,\n",
    "        \"saturation_delta\": 0.5,\n",
    "        \"brightness_prob\": 0.5,\n",
    "        \"brightness_delta\": 0.125\n",
    "    },\n",
    "    \"rsm_strategy\": {\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    },\n",
    "    \"momentum_strategy\": {\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"decay_steps\": 2 ** 7,\n",
    "        \"decay_rate\": 0.8\n",
    "    },\n",
    "    \"early_stop\": {\n",
    "        \"sample_frequency\": 50,\n",
    "        \"successive_limit\": 3,\n",
    "        \"min_loss\": 2.5,\n",
    "        \"min_curr_map\": 0.84\n",
    "    }\n",
    "}\n",
    "\n",
    "print('ok lalalalala')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用paddle搭建yolov3模型\n",
    "定义两个类，分别代表 Yolo-v3 和 Yolo-v3-tiny 两个模型。跟随其后的是模型选择函数，根据配置使用不同的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "class YOLOv3(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []\n",
    "        self.downsample_ratio = 1\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.anchors = anchors\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3'\n",
    "\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                num_filters,\n",
    "                filter_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                use_cudnn=True):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            act=None,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "            bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        # 在batch_norm中使用 leaky 的话，只能使用默认的 alpha=0.02；如果需要设值，必须提出去单独来\n",
    "        out = fluid.layers.batch_norm(\n",
    "            input=conv, act=None, \n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02), regularizer=L2Decay(0.)),\n",
    "            bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "        out = fluid.layers.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "    def downsample(self, input, num_filters, filter_size=3, stride=2, padding=1):\n",
    "        self.downsample_ratio *= 2\n",
    "        return self.conv_bn(input, \n",
    "                num_filters=num_filters, \n",
    "                filter_size=filter_size, \n",
    "                stride=stride, \n",
    "                padding=padding)\n",
    "\n",
    "    def basicblock(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        conv2 = self.conv_bn(conv1, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        out = fluid.layers.elementwise_add(x=input, y=conv2, act=None)\n",
    "        return out\n",
    "\n",
    "    def layer_warp(self, input, num_filters, count):\n",
    "        res_out = self.basicblock(input, num_filters)\n",
    "        for j in range(1, count):\n",
    "            res_out = self.basicblock(res_out, num_filters)\n",
    "        return res_out\n",
    "\n",
    "    def upsample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        out = fluid.layers.resize_nearest(\n",
    "            input=input,\n",
    "            scale=scale,\n",
    "            actual_shape=out_shape)\n",
    "        return out\n",
    "    \n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        assert num_filters % 2 == 0, \"num_filters {} cannot be divided by 2\".format(num_filters)\n",
    "        conv = input\n",
    "        for j in range(2):\n",
    "            conv = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "            conv = self.conv_bn(conv, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        route = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    def net(self, img): \n",
    "        # darknet\n",
    "        stages = [1,2,8,8,4]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than downsample times\"\n",
    "        # 256x256\n",
    "        conv1 = self.conv_bn(img, num_filters=32, filter_size=3, stride=1, padding=1)\n",
    "        downsample_  = self.downsample(conv1, conv1.shape[1] * 2)\n",
    "        blocks = []\n",
    "\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            block = self.layer_warp(downsample_, 32 *(2**i), stage_count)\n",
    "            blocks.append(block)\n",
    "            if i < len(stages) - 1:\n",
    "                downsample_ = self.downsample(block, block.shape[1]*2)\n",
    "        blocks = blocks[-1:-4:-1]   # 取倒数三层，并且逆序，后面跨层级联需要\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo 中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)\n",
    "            route, tip = self.yolo_detection_block(block, num_filters=512 // (2**i))\n",
    "            block_out = fluid.layers.conv2d(\n",
    "                input=tip,\n",
    "                num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),      # 5 elements represent x|y|h|w|score\n",
    "                filter_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                act=None,\n",
    "                param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "                bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "            self.outputs.append(block_out)\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 256//(2**i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.upsample(route)\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "class YOLOv3Tiny(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []\n",
    "        self.downsample_ratio = 1\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.anchors = anchors\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3-tiny'\n",
    "\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                num_filters,\n",
    "                filter_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                num_groups=1,\n",
    "                use_cudnn=True):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            act=None,\n",
    "            groups=num_groups,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "            bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        out = fluid.layers.batch_norm(\n",
    "            input=conv, act='relu', \n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02), regularizer=L2Decay(0.)),\n",
    "            bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def depthwise_conv_bn(self, input, filter_size=3, stride=1, padding=1):\n",
    "        num_filters = input.shape[1]\n",
    "        return self.conv_bn(input, \n",
    "                num_filters=num_filters, \n",
    "                filter_size=filter_size, \n",
    "                stride=stride, \n",
    "                padding=padding, \n",
    "                num_groups=num_filters)\n",
    "\n",
    "    def downsample(self, input, pool_size=2, pool_stride=2):\n",
    "        self.downsample_ratio *= 2\n",
    "        return fluid.layers.pool2d(input=input, pool_type='max', pool_size=pool_size,\n",
    "                                    pool_stride=pool_stride)\n",
    "\n",
    "    def basicblock(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=3, stride=1, padding=1)\n",
    "        out = self.downsample(conv1)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def upsample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        out = fluid.layers.resize_nearest(\n",
    "            input=input,\n",
    "            scale=scale,\n",
    "            actual_shape=out_shape)\n",
    "        return out\n",
    "    \n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        route = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    def net(self, img): \n",
    "        # darknet-tiny\n",
    "        stages = [16, 32, 64, 128, 256, 512]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than downsample times\"\n",
    "        # 256x256\n",
    "        tmp = img\n",
    "        blocks = []\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            if i == len(stages) - 1:\n",
    "                block = self.conv_bn(tmp, stage_count, filter_size=3, stride=1, padding=1)\n",
    "                blocks.append(block)\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.conv_bn(blocks[-1], stage_count * 2, filter_size=1, stride=1, padding=0)\n",
    "                blocks.append(block)\n",
    "            else:\n",
    "                tmp = self.basicblock(tmp, stage_count)\n",
    "                blocks.append(tmp)\n",
    "        \n",
    "        blocks = [blocks[-1], blocks[3]]\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo 中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)\n",
    "            if i < 1:\n",
    "                route, tip = self.yolo_detection_block(block, num_filters=256 // (2**i))\n",
    "            else:\n",
    "                tip = self.conv_bn(block, num_filters=256, filter_size=3, stride=1, padding=1)\n",
    "            block_out = fluid.layers.conv2d(\n",
    "                input=tip,\n",
    "                num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),      # 5 elements represent x|y|h|w|score\n",
    "                filter_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                act=None,\n",
    "                param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "                bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "            self.outputs.append(block_out)\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 128 // (2**i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.upsample(route)\n",
    "\n",
    "        return self.outputs\n",
    "        \n",
    "\n",
    "def get_yolo(is_tiny, class_num, anchors, anchor_mask):\n",
    "    if is_tiny:\n",
    "        print('USE YOLOv3Tiny')\n",
    "        return YOLOv3Tiny(class_num, anchors, anchor_mask)\n",
    "    else:\n",
    "        print('USE YOLOv3')\n",
    "        return YOLOv3(class_num, anchors, anchor_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义初始化相关函数\n",
    "* init_train_parameters()主要作用是得到本数据集的class_dim（种类）,还有本数据集的总训练样本数image_count；\n",
    "\n",
    "* init_log_config():初始化日志的相关配置；\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_parameters():\n",
    "    \"\"\"\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file_list = os.path.join(train_parameters['data_dir'], train_parameters['file_list'])\n",
    "    label_list = os.path.join(train_parameters['data_dir'], \"label_list\")\n",
    "    index = 0\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        for line in lines:\n",
    "            train_parameters['label_dict'][line.strip()] = index\n",
    "            index += 1\n",
    "        train_parameters['class_dim'] = index\n",
    "    with codecs.open(file_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        train_parameters['image_count'] = len(lines)\n",
    "\n",
    "\n",
    "def init_log_config():\n",
    "    \"\"\"\n",
    "    初始化日志相关配置\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\n",
    "    if not os.path.exists(log_path):\n",
    "        os.makedirs(log_path)\n",
    "    log_name = os.path.join(log_path, 'train.log')\n",
    "    sh = logging.StreamHandler()\n",
    "    fh = logging.FileHandler(log_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像增强处理的系列函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_to_center_relative(box, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Convert COCO annotations box with format [x1, y1, w, h] to \n",
    "    center mode [center_x, center_y, w, h] and divide image width\n",
    "    and height to get relative value in range[0, 1]\n",
    "    \"\"\"\n",
    "    assert len(box) == 4, \"box should be a len(4) list or tuple\"\n",
    "    x, y, w, h = box\n",
    "\n",
    "    x1 = max(x, 0)\n",
    "    x2 = min(x + w - 1, img_width - 1)\n",
    "    y1 = max(y, 0)\n",
    "    y2 = min(y + h - 1, img_height - 1)\n",
    "\n",
    "    x = (x1 + x2) / 2 / img_width\n",
    "    y = (y1 + y2) / 2 / img_height\n",
    "    w = (x2 - x1) / img_width\n",
    "    h = (y2 - y1) / img_height\n",
    "\n",
    "    return np.array([x, y, w, h])\n",
    "\n",
    "\n",
    "def resize_img(img, sampled_labels, input_size):\n",
    "    target_size = input_size\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def box_iou_xywh(box1, box2):\n",
    "    assert box1.shape[-1] == 4, \"Box1 shape[-1] should be 4.\"\n",
    "    assert box2.shape[-1] == 4, \"Box2 shape[-1] should be 4.\"\n",
    "\n",
    "    b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "    b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "    b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "    b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "    inter_x1 = np.maximum(b1_x1, b2_x1)\n",
    "    inter_x2 = np.minimum(b1_x2, b2_x2)\n",
    "    inter_y1 = np.maximum(b1_y1, b2_y1)\n",
    "    inter_y2 = np.minimum(b1_y2, b2_y2)\n",
    "    inter_w = inter_x2 - inter_x1 + 1\n",
    "    inter_h = inter_y2 - inter_y1 + 1\n",
    "    inter_w[inter_w < 0] = 0\n",
    "    inter_h[inter_h < 0] = 0\n",
    "\n",
    "    inter_area = inter_w * inter_h\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    return inter_area / (b1_area + b2_area - inter_area)\n",
    "\n",
    "\n",
    "def box_crop(boxes, labels, crop, img_shape):\n",
    "    x, y, w, h = map(float, crop)\n",
    "    im_w, im_h = map(float, img_shape)\n",
    "\n",
    "    boxes = boxes.copy()\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] - boxes[:, 2] / 2) * im_w, (boxes[:, 0] + boxes[:, 2] / 2) * im_w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] - boxes[:, 3] / 2) * im_h, (boxes[:, 1] + boxes[:, 3] / 2) * im_h\n",
    "\n",
    "    crop_box = np.array([x, y, x + w, y + h])\n",
    "    centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0\n",
    "    mask = np.logical_and(crop_box[:2] <= centers, centers <= crop_box[2:]).all(axis=1)\n",
    "\n",
    "    boxes[:, :2] = np.maximum(boxes[:, :2], crop_box[:2])\n",
    "    boxes[:, 2:] = np.minimum(boxes[:, 2:], crop_box[2:])\n",
    "    boxes[:, :2] -= crop_box[:2]\n",
    "    boxes[:, 2:] -= crop_box[:2]\n",
    "\n",
    "    mask = np.logical_and(mask, (boxes[:, :2] < boxes[:, 2:]).all(axis=1))\n",
    "    boxes = boxes * np.expand_dims(mask.astype('float32'), axis=1)\n",
    "    labels = labels * mask.astype('float32')\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] + boxes[:, 2]) / 2 / w, (boxes[:, 2] - boxes[:, 0]) / w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] + boxes[:, 3]) / 2 / h, (boxes[:, 3] - boxes[:, 1]) / h\n",
    "\n",
    "    return boxes, labels, mask.sum()\n",
    "\n",
    "\n",
    "def random_brightness(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['brightness_prob']:\n",
    "        brightness_delta = train_parameters['image_distort_strategy']['brightness_delta']\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['contrast_prob']:\n",
    "        contrast_delta = train_parameters['image_distort_strategy']['contrast_delta']\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['saturation_prob']:\n",
    "        saturation_delta = train_parameters['image_distort_strategy']['saturation_delta']\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['hue_prob']:\n",
    "        hue_delta = train_parameters['image_distort_strategy']['hue_delta']\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_image(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob > 0.5:\n",
    "        img = random_brightness(img)\n",
    "        img = random_contrast(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "    else:\n",
    "        img = random_brightness(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "        img = random_contrast(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_crop(img, boxes, labels, scales=[0.3, 1.0], max_ratio=2.0, constraints=None, max_trial=50):\n",
    "    if random.random() > 0.6:\n",
    "        return img, boxes, labels\n",
    "    if len(boxes) == 0:\n",
    "        return img, boxes, labels\n",
    "\n",
    "    if not constraints:\n",
    "        constraints = [\n",
    "                (0.1, 1.0),\n",
    "                (0.3, 1.0),\n",
    "                (0.5, 1.0),\n",
    "                (0.7, 1.0),\n",
    "                (0.9, 1.0),\n",
    "                (0.0, 1.0)]\n",
    "\n",
    "    w, h = img.size\n",
    "    crops = [(0, 0, w, h)]\n",
    "    for min_iou, max_iou in constraints:\n",
    "        for _ in range(max_trial):\n",
    "            scale = random.uniform(scales[0], scales[1])\n",
    "            aspect_ratio = random.uniform(max(1 / max_ratio, scale * scale), \\\n",
    "                                          min(max_ratio, 1 / scale / scale))\n",
    "            crop_h = int(h * scale / np.sqrt(aspect_ratio))\n",
    "            crop_w = int(w * scale * np.sqrt(aspect_ratio))\n",
    "            crop_x = random.randrange(w - crop_w)\n",
    "            crop_y = random.randrange(h - crop_h)\n",
    "            crop_box = np.array([[\n",
    "                (crop_x + crop_w / 2.0) / w,\n",
    "                (crop_y + crop_h / 2.0) / h,\n",
    "                crop_w / float(w),\n",
    "                crop_h /float(h)\n",
    "                ]])\n",
    "\n",
    "            iou = box_iou_xywh(crop_box, boxes)\n",
    "            if min_iou <= iou.min() and max_iou >= iou.max():\n",
    "                crops.append((crop_x, crop_y, crop_w, crop_h))\n",
    "                break\n",
    "\n",
    "    while crops:\n",
    "        crop = crops.pop(np.random.randint(0, len(crops)))\n",
    "        crop_boxes, crop_labels, box_num = box_crop(boxes, labels, crop, (w, h))\n",
    "        if box_num < 1:\n",
    "            continue\n",
    "        img = img.crop((crop[0], crop[1], crop[0] + crop[2], \n",
    "                        crop[1] + crop[3])).resize(img.size, Image.LANCZOS)\n",
    "        return img, crop_boxes, crop_labels\n",
    "    return img, boxes, labels\n",
    "\n",
    "\n",
    "def random_expand(img, gtboxes, keep_ratio=True):\n",
    "    if np.random.uniform(0, 1) < train_parameters['image_distort_strategy']['expand_prob']:\n",
    "        return img, gtboxes\n",
    "\n",
    "    max_ratio = train_parameters['image_distort_strategy']['expand_max_ratio']    \n",
    "    w, h = img.size\n",
    "    c = 3\n",
    "    ratio_x = random.uniform(1, max_ratio)\n",
    "    if keep_ratio:\n",
    "        ratio_y = ratio_x\n",
    "    else:\n",
    "        ratio_y = random.uniform(1, max_ratio)\n",
    "    oh = int(h * ratio_y)\n",
    "    ow = int(w * ratio_x)\n",
    "    off_x = random.randint(0, ow -w)\n",
    "    off_y = random.randint(0, oh -h)\n",
    "\n",
    "    out_img = np.zeros((oh, ow, c), np.uint8)\n",
    "    for i in range(c):\n",
    "        out_img[:, :, i] = train_parameters['mean_rgb'][i]\n",
    "\n",
    "    out_img[off_y: off_y + h, off_x: off_x + w, :] = img\n",
    "    gtboxes[:, 0] = ((gtboxes[:, 0] * w) + off_x) / float(ow)\n",
    "    gtboxes[:, 1] = ((gtboxes[:, 1] * h) + off_y) / float(oh)\n",
    "    gtboxes[:, 2] = gtboxes[:, 2] / ratio_x\n",
    "    gtboxes[:, 3] = gtboxes[:, 3] / ratio_y\n",
    "\n",
    "    return Image.fromarray(out_img), gtboxes\n",
    "\n",
    "\n",
    "def preprocess(img, bbox_labels, input_size, mode):\n",
    "    img_width, img_height = img.size\n",
    "    sample_labels = np.array(bbox_labels)\n",
    "    if mode == 'train':\n",
    "        if train_parameters['apply_distort']:\n",
    "            img = distort_image(img)\n",
    "        img, gtboxes = random_expand(img, sample_labels[:, 1:5])\n",
    "        img, gtboxes, gtlabels = random_crop(img, gtboxes, sample_labels[:, 0])\n",
    "        sample_labels[:, 0] = gtlabels\n",
    "        sample_labels[:, 1:5] = gtboxes\n",
    "    img = resize_img(img, sample_labels, input_size)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img -= train_parameters['mean_rgb']\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "    img *= 0.007843\n",
    "    return img, sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_reader(file_list, data_dir, input_size, mode):\n",
    "    def reader():\n",
    "        np.random.shuffle(file_list)\n",
    "        for line in file_list:\n",
    "            if mode == 'train' or mode == 'eval':\n",
    "                \n",
    "                parts = line.split('\\t')\n",
    "                image_path = parts[0]\n",
    "                img = Image.open(image_path)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                im_width, im_height = img.size\n",
    "                # bbox 的列表，每一个元素为这样\n",
    "                # layout: label | x-center | y-cneter | width | height | difficult\n",
    "                bbox_labels = []\n",
    "                for object_str in parts[1:]:\n",
    "                    if len(object_str) <= 1:\n",
    "                        continue\n",
    "                    bbox_sample = []\n",
    "                    object = json.loads(object_str)\n",
    "                    bbox_sample.append(float(train_parameters['label_dict'][object['value']]))\n",
    "                    bbox = object['coordinate']\n",
    "                    box = [bbox[0][0], bbox[0][1], bbox[1][0] - bbox[0][0], bbox[1][1] - bbox[0][1]]\n",
    "                    bbox = box_to_center_relative(box, im_height, im_width)\n",
    "                    bbox_sample.append(float(bbox[0]))\n",
    "                    bbox_sample.append(float(bbox[1]))\n",
    "                    bbox_sample.append(float(bbox[2]))\n",
    "                    bbox_sample.append(float(bbox[3]))\n",
    "                    difficult = float(0)\n",
    "                    bbox_sample.append(difficult)\n",
    "                    bbox_labels.append(bbox_sample)\n",
    "                \n",
    "                if len(bbox_labels) == 0: continue\n",
    "                img, sample_labels = preprocess(img, bbox_labels, input_size, mode)\n",
    "                # sample_labels = np.array(sample_labels)\n",
    "                if len(sample_labels) == 0: continue\n",
    "                boxes = sample_labels[:, 1:5]\n",
    "                lbls = sample_labels[:, 0].astype('int32')\n",
    "                difficults = sample_labels[:, -1].astype('int32')\n",
    "                max_box_num = train_parameters['max_box_num']\n",
    "                cope_size = max_box_num if len(boxes) >= max_box_num else len(boxes)\n",
    "                ret_boxes = np.zeros((max_box_num, 4), dtype=np.float32)\n",
    "                ret_lbls = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_difficults = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_boxes[0: cope_size] = boxes[0: cope_size]\n",
    "                ret_lbls[0: cope_size] = lbls[0: cope_size]\n",
    "                ret_difficults[0: cope_size] = difficults[0: cope_size]\n",
    "                yield img, ret_boxes, ret_lbls, ret_difficults\n",
    "            elif mode == 'test':\n",
    "                img_path = os.path.join(line)\n",
    "                yield Image.open(img_path)\n",
    "\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 训练准备\n",
    "* 定义异步数据读取\n",
    "\n",
    "* 定义优化器\n",
    "\n",
    "* 参数创建完成后，我们需要定义一个优化器optimizer，为了改善模型的训练速度以及效果，学术界先后提出了很多优化算法，包括： Momentum、RMSProp、Adam 等，已经被封装在fluid内部，读者可直接调用。\n",
    "\n",
    "* 构建 program 和损失函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process_custom_reader(file_path, data_dir, num_workers, input_size, mode):\n",
    "    file_path = os.path.join(data_dir, file_path)\n",
    "    readers = []\n",
    "    images = [line.strip() for line in open(file_path)]\n",
    "    n = int(math.ceil(len(images) // num_workers))\n",
    "    image_lists = [images[i: i + n] for i in range(0, len(images), n)]\n",
    "    for l in image_lists:\n",
    "        readers.append(paddle.batch(custom_reader(l, data_dir, input_size, mode), \n",
    "                                    batch_size=train_parameters['train_batch_size']))\n",
    "    return paddle.reader.multiprocess_reader(readers, False)\n",
    "\n",
    "\n",
    "def create_eval_reader(file_path, data_dir, input_size, mode):\n",
    "    file_path = os.path.join(data_dir, file_path)\n",
    "    images = [line.strip() for line in open(file_path)]\n",
    "    return paddle.batch(custom_reader(images, data_dir, input_size, mode), \n",
    "                        batch_size=train_parameters['train_batch_size'],\n",
    "                        drop_last=True)\n",
    "\n",
    "\n",
    "def optimizer_momentum_setting():\n",
    "    learning_strategy = train_parameters['momentum_strategy']\n",
    "    learning_rate = fluid.layers.exponential_decay(learning_rate=learning_strategy['learning_rate'],\n",
    "                                                   decay_steps=learning_strategy['decay_steps'],\n",
    "                                                   decay_rate=learning_strategy['decay_rate'])\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.1)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_rms_setting():\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\n",
    "    learning_strategy = train_parameters['rsm_strategy']\n",
    "    lr = learning_strategy['learning_rate']\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "\n",
    "    optimizer = fluid.optimizer.RMSProp(\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values),\n",
    "        regularization=fluid.regularizer.L2Decay(0.00005))\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def build_train_program_with_async_reader(main_prog, startup_prog):\n",
    "    max_box_num = train_parameters['max_box_num']\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        img = fluid.layers.data(name='img', shape=yolo_config['input_size'], dtype='float32')\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[max_box_num, 4], dtype='float32', lod_level=0)\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[max_box_num], dtype='int32', lod_level=0)\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[max_box_num], dtype='int32', lod_level=0)\n",
    "        data_reader = fluid.layers.create_py_reader_by_data(capacity=train_parameters['train_batch_size'],\n",
    "                                                            feed_list=[img, gt_box, gt_label, difficult],\n",
    "                                                            name='train')\n",
    "        multi_reader = multi_process_custom_reader(train_parameters['file_list'],\n",
    "                                                   train_parameters['data_dir'],\n",
    "                                                   train_parameters['multi_data_reader_count'],\n",
    "                                                   yolo_config['input_size'],\n",
    "                                                   'train')\n",
    "        data_reader.decorate_paddle_reader(multi_reader)\n",
    "        with fluid.unique_name.guard():\n",
    "            img, gt_box, gt_label, difficult = fluid.layers.read_file(data_reader)\n",
    "            model = get_yolo(ues_tiny, train_parameters['class_dim'], yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "            outputs = model.net(img)\n",
    "            losses = []\n",
    "            downsample_ratio = model.get_downsample_ratio()\n",
    "            with fluid.unique_name.guard('train'):\n",
    "                for i, out in enumerate(outputs):\n",
    "                    logger.info(\"{0} downsample_ratio: {1} output:{2}\".format(i, downsample_ratio, out))\n",
    "                    loss = fluid.layers.yolov3_loss(\n",
    "                            x=out,\n",
    "                            gtbox=gt_box,\n",
    "                            gtlabel=gt_label,\n",
    "                            anchors=model.get_anchors(),\n",
    "                            anchor_mask=model.get_anchor_mask()[i],\n",
    "                            class_num=model.get_class_num(),\n",
    "                            ignore_thresh=train_parameters['ignore_thresh'],\n",
    "                            downsample_ratio=downsample_ratio)\n",
    "                    losses.append(fluid.layers.reduce_mean(loss))\n",
    "                    downsample_ratio //= 2\n",
    "                loss = sum(losses)\n",
    "                optimizer = optimizer_rms_setting()\n",
    "                optimizer.minimize(loss)\n",
    "                return data_reader, loss\n",
    "\n",
    "\n",
    "def build_eval_program_with_feeder(main_prog, startup_prog, place):\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        img = fluid.layers.data(name='img', shape=yolo_config['input_size'], dtype='float32')\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[4], dtype='float32', lod_level=1)\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[1], dtype='int32', lod_level=1)\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[1], dtype='int32', lod_level=1)\n",
    "        feeder = fluid.DataFeeder(feed_list=[img, gt_box, gt_label, difficult], place=place, program=main_prog)\n",
    "        reader = create_eval_reader(train_parameters['file_list'], train_parameters['data_dir'], \n",
    "                                    yolo_config['input_size'], 'eval')\n",
    "        with fluid.unique_name.guard():\n",
    "            model = get_yolo(ues_tiny, train_parameters['class_dim'], yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "            outputs = model.net(img)\n",
    "            return feeder, reader, outputs, gt_box, gt_label, difficult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入已有模型\n",
    "定义一个函数load_pretrained_params()，来做两个选择：\n",
    "\n",
    "①如果train_parameters['continue_train'] = true 则在上次保存的模型基础上继续训练；\n",
    "\n",
    "②如果train_parameters['continue_train'] = False，且train_parameters['pretrained'] = True，则使用预训练模型；\n",
    "\n",
    "③但是要注意，因为代码中使用的是if ...elif ...所以，如果train_parameters['continue_train'] = True，则不会执行elif，也就是不会加载预训练模型；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_params(exe, program):\n",
    "    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_model_dir']):\n",
    "        logger.info('load param from retrain model')\n",
    "        fluid.io.load_persistables(executor=exe,\n",
    "                                   dirname=train_parameters['save_model_dir'],\n",
    "                                   main_program=program)\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_model_dir']):\n",
    "        logger.info('load param from pretrained model')\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_model_dir'], var.name))\n",
    "\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_model_dir'], main_program=program,\n",
    "                           predicate=if_exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练\n",
    "接下来，我们就定义一个train()方法，然后就可以调用这个方法，来执行训练了； train()方法里有几个工作要做，比如：\n",
    "\n",
    "１．定义训练场所：\n",
    "\n",
    "２．定义执行器： 为了能够运行开发者定义的网络拓扑结构和优化器，需要定义执行器。由执行器来真正的执行参数的初始化和网络的训练过程。fulid使用了一个C++类Executor用于运行一个程序，Executor类似一个解释器，Fluid将会使用这样一个解析器来训练和测试模型。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    init_log_config()\n",
    "    init_train_parameters()\n",
    "    logger.info(\"start train YOLOv3, train params:%s\", str(train_parameters))\n",
    "\n",
    "    logger.info(\"create place, use gpu:\" + str(train_parameters['use_gpu']))\n",
    "    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\n",
    "\n",
    "    logger.info(\"build network and program\")\n",
    "    train_program = fluid.Program()\n",
    "    start_program = fluid.Program()\n",
    "    eval_program = fluid.Program()\n",
    "    start_program = fluid.Program()\n",
    "    train_reader, loss = build_train_program_with_async_reader(train_program, start_program)\n",
    "    eval_feeder, eval_reader, outputs, gt_box, gt_label, difficult = build_eval_program_with_feeder(eval_program, start_program, place)\n",
    "    eval_program = eval_program.clone(for_test=True)\n",
    "\n",
    "    logger.info(\"build executor and init params\")\n",
    "    exe = fluid.Executor(place)\n",
    "    exe.run(start_program)\n",
    "    train_fetch_list = [loss.name]\n",
    "    eval_fetch_list = [v.name for v in outputs]\n",
    "    load_pretrained_params(exe, train_program)\n",
    "\n",
    "\n",
    "    stop_strategy = train_parameters['early_stop']\n",
    "    successive_limit = stop_strategy['successive_limit']\n",
    "    sample_freq = stop_strategy['sample_frequency']\n",
    "    min_curr_map = stop_strategy['min_curr_map']\n",
    "    min_loss = stop_strategy['min_loss']\n",
    "    stop_train = False\n",
    "    successive_count = 0\n",
    "    total_batch_count = 0\n",
    "    valid_thresh = train_parameters['valid_thresh']\n",
    "    nms_thresh = train_parameters['nms_thresh']\n",
    "    for pass_id in range(train_parameters[\"num_epochs\"]):\n",
    "        logger.info(\"current pass: %d, start read image\", pass_id)\n",
    "        batch_id = 0\n",
    "        train_reader.start()\n",
    "        try:\n",
    "            while True:\n",
    "                t1 = time.time()\n",
    "                loss = exe.run(train_program, fetch_list=train_fetch_list)\n",
    "                period = time.time() - t1\n",
    "                loss = np.mean(np.array(loss))\n",
    "                batch_id += 1\n",
    "                total_batch_count += 1\n",
    "\n",
    "                if batch_id % 10 == 0:\n",
    "                    logger.info(\n",
    "                        \"Pass {0}, trainbatch {1}, loss {2} time {3}\".format(pass_id, batch_id, loss, \"%2.2f sec\" % period))\n",
    "                # 采用简单的定时采样停止办法，可以调整为更精细的保存策略\n",
    "                if total_batch_count % 100 == 0:\n",
    "                    logger.info(\"temp save {0} batch train result\".format(total_batch_count))\n",
    "                    fluid.io.save_persistables(dirname=train_parameters['save_model_dir'],\n",
    "                                               main_program=train_program,\n",
    "                                               executor=exe)\n",
    "        except fluid.core.EOFException:\n",
    "            train_reader.reset()\n",
    "\n",
    "    logger.info(\"training till last epcho, end training\")\n",
    "    fluid.io.save_persistables(dirname=train_parameters['save_model_dir'], main_program=train_program, executor=exe)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型压缩\n",
    "我们可以将训练好的模型进行压缩带一个压缩包里，这样方便复制和移动；\n",
    "\n",
    "注意： 这一条是linux命令，和编程是没有关系的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cf yolo-model.tar yolo-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型固化\n",
    "接下来我们把训练好的模型进行固化，为什么需要把模型进行固化呢？是因为：\n",
    "\n",
    "1.训练后保存的模型，有很多保留项，比如有优化器的、BN等，（比如本次yolo-model里面有1034项）；\n",
    "\n",
    "2.固化后的模型，只保留和主模型有关的，和预测有关的项的参数，（比如本次固化后的freeze_model里面有367项）；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_dict = {}\n",
    "with codecs.open('data/data7085/label_list.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        label_dict[float(parts[0])] = parts[1]\n",
    "print(label_dict)\n",
    "class_dim = len(label_dict)\n",
    "\n",
    "def freeze_model():\n",
    "\n",
    "    path = \"./yolo-model\"\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    model = model = get_yolo(ues_tiny, class_dim, yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "    image = fluid.layers.data(name='image', shape=yolo_config['input_size'], dtype='float32')\n",
    "    pred = model.net(image)\n",
    "    \n",
    "    freeze_program = fluid.default_main_program()\n",
    "    fluid.io.load_persistables(exe, path, freeze_program)\n",
    "    freeze_program = freeze_program.clone(for_test=True)\n",
    "\n",
    "    fluid.io.save_inference_model(\"./freeze_model\", ['image'], pred, exe, freeze_program)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#接下来这一条还是linux命令；\n",
    "#把固化的模型就行压缩\n",
    "!tar -cf freeze_yolov3_model.tar freeze_yolov3_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测阶段\n",
    "接下来我们开始预测阶段，此阶段我们主要有以下工作：\n",
    "\n",
    "1.定义几个用于画图的方法，目的是在预测出的结果上可视化边界框，并标出类别；\n",
    "\n",
    "2.定义预测方法infer(),我们可以直接调用这个infer()方法来执行预测； \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "\n",
    "\n",
    "ues_tiny = train_parameters['use_tiny']\n",
    "yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "\n",
    "target_size = yolo_config['input_size']\n",
    "anchors = yolo_config['anchors']\n",
    "anchor_mask = yolo_config['anchor_mask']\n",
    "\n",
    "nms_threshold = 0.4\n",
    "valid_thresh = 0.4\n",
    "confs_threshold = 0.5\n",
    "label_dict = {}\n",
    "with codecs.open('data/data7085/label_list.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        label_dict[str(float(parts[0]))] = parts[1]\n",
    "print(label_dict)\n",
    "class_dim = len(label_dict)\n",
    "\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "path = \"./freeze_yolov3_model\"\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=path, executor=exe)\n",
    "\n",
    "\n",
    "def get_yolo_anchors_classes(class_num, anchors, anchor_mask):\n",
    "    yolo_anchors = []\n",
    "    yolo_classes = []\n",
    "    for mask_pair in anchor_mask:\n",
    "        mask_anchors = []\n",
    "        for mask in mask_pair:\n",
    "            mask_anchors.append(anchors[2 * mask])\n",
    "            mask_anchors.append(anchors[2 * mask + 1])\n",
    "        yolo_anchors.append(mask_anchors)\n",
    "        yolo_classes.append(class_num)\n",
    "    return yolo_anchors, yolo_classes\n",
    "\n",
    "\n",
    "def draw_bbox_image(img, boxes, labels, save_name):\n",
    "    \"\"\"\n",
    "    给图片画上外接矩形框\n",
    "    :param img:\n",
    "    :param boxes:\n",
    "    :param save_name:\n",
    "    :param labels\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # font = ImageFont.truetype(\"font.ttf\", 25)\n",
    "    img_width, img_height = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box, label in zip(boxes, labels):\n",
    "        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]\n",
    "        draw.rectangle((xmin, ymin, xmax, ymax), None, 'red')\n",
    "        draw.text((xmin, ymin), label_dict[str(label)], (255, 255, 0))\n",
    "    img.save(save_name)\n",
    "    return img\n",
    "\n",
    "\n",
    "def clip_bbox(bbox):\n",
    "    \"\"\"\n",
    "    截断矩形框\n",
    "    :param bbox:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    xmin = max(min(bbox[0], 1.), 0.)\n",
    "    ymin = max(min(bbox[1], 1.), 0.)\n",
    "    xmax = max(min(bbox[2], 1.), 0.)\n",
    "    ymax = max(min(bbox[3], 1.), 0.)\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def resize_img(img, target_size):\n",
    "    \"\"\"\n",
    "    保持比例的缩放图片\n",
    "    :param img:\n",
    "    :param target_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = img.resize(target_size[1:], Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_image(img_path):\n",
    "    \"\"\"\n",
    "    读取图片\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin = Image.open(img_path)\n",
    "    img = resize_img(origin, target_size)\n",
    "    resized_img = img.copy()\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = np.array(img).astype('float32').transpose((2, 0, 1))  # HWC to CHW\n",
    "    img -= 127.5\n",
    "    img *= 0.007843\n",
    "    img = img[np.newaxis, :]\n",
    "    return origin, img, resized_img\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Perform sigmoid to input numpy array\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * x))\n",
    "\n",
    "\n",
    "def box_xywh_to_xyxy(box):\n",
    "    \"\"\"\n",
    "    bbox 两种形式的转换，左上角和宽高---->左上角|右下角\n",
    "    :param box:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    shape = box.shape\n",
    "    assert shape[-1] == 4, \"Box shape[-1] should be 4.\"\n",
    "\n",
    "    box = box.reshape((-1, 4))\n",
    "    box[:, 0], box[:, 2] = box[:, 0] - box[:, 2] / 2, box[:, 0] + box[:, 2] / 2\n",
    "    box[:, 1], box[:, 3] = box[:, 1] - box[:, 3] / 2, box[:, 1] + box[:, 3] / 2\n",
    "    box = box.reshape(shape)\n",
    "    return box\n",
    "\n",
    "\n",
    "def box_iou_xyxy(box1, box2):\n",
    "    assert box1.shape[-1] == 4, \"Box1 shape[-1] should be 4.\"\n",
    "    assert box2.shape[-1] == 4, \"Box2 shape[-1] should be 4.\"\n",
    "\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    inter_x1 = np.maximum(b1_x1, b2_x1)\n",
    "    inter_x2 = np.minimum(b1_x2, b2_x2)\n",
    "    inter_y1 = np.maximum(b1_y1, b2_y1)\n",
    "    inter_y2 = np.minimum(b1_y2, b2_y2)\n",
    "    inter_w = inter_x2 - inter_x1\n",
    "    inter_h = inter_y2 - inter_y1\n",
    "    inter_w[inter_w < 0] = 0\n",
    "    inter_h[inter_h < 0] = 0\n",
    "\n",
    "    inter_area = inter_w * inter_h\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "    \n",
    "    return inter_area / (b1_area + b2_area - inter_area)\n",
    "\n",
    "\n",
    "def rescale_box_in_input_image(boxes, im_shape, input_size):\n",
    "    \"\"\"Scale (x1, x2, y1, y2) box of yolo output to input image\"\"\"\n",
    "    h, w = im_shape\n",
    "    fx = w / input_size\n",
    "    fy = h / input_size\n",
    "    boxes[:, 0] *= fx\n",
    "    boxes[:, 1] *= fy\n",
    "    boxes[:, 2] *= fx\n",
    "    boxes[:, 3] *= fy\n",
    "    boxes[boxes<0] = 0\n",
    "    boxes[:, 2][boxes[:, 2] > (w - 1)] = w - 1\n",
    "    boxes[:, 3][boxes[:, 3] > (h - 1)] = h - 1\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def get_yolo_detection(preds, anchors, class_num, img_height, img_width):\n",
    "    \"\"\"Get yolo box, confidence score, class label from Darknet53 output\"\"\"\n",
    "    preds_n = np.array(preds)\n",
    "    n, c, h, w = preds_n.shape\n",
    "    print(preds_n.shape, anchors)\n",
    "    anchor_num = len(anchors) // 2\n",
    "    preds_n = preds_n.reshape([n, anchor_num, class_num + 5, h, w]).transpose((0, 1, 3, 4, 2))\n",
    "    preds_n[:, :, :, :, :2] = sigmoid(preds_n[:, :, :, :, :2])\n",
    "    preds_n[:, :, :, :, 4:] = sigmoid(preds_n[:, :, :, :, 4:])\n",
    "\n",
    "    pred_boxes = preds_n[:, :, :, :, :4]\n",
    "    pred_confs = preds_n[:, :, :, :, 4]\n",
    "    pred_scores = preds_n[:, :, :, :, 5:] * np.expand_dims(pred_confs, axis=4)\n",
    "\n",
    "    grid_x = np.tile(np.arange(w).reshape((1, w)), (h, 1))\n",
    "    grid_y = np.tile(np.arange(h).reshape((h, 1)), (1, w))\n",
    "    anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
    "    anchors_s = np.array([(an_w, an_h) for an_w, an_h in anchors])\n",
    "    anchor_w = anchors_s[:, 0:1].reshape((1, anchor_num, 1, 1))\n",
    "    anchor_h = anchors_s[:, 1:2].reshape((1, anchor_num, 1, 1))\n",
    "\n",
    "    pred_boxes[:, :, :, :, 0] += grid_x\n",
    "    pred_boxes[:, :, :, :, 1] += grid_y\n",
    "    pred_boxes[:, :, :, :, 2] = np.exp(pred_boxes[:, :, :, :, 2]) * anchor_w\n",
    "    pred_boxes[:, :, :, :, 3] = np.exp(pred_boxes[:, :, :, :, 3]) * anchor_h\n",
    "    \n",
    "    pred_boxes[:, :, :, :, 0] = pred_boxes[:, :, :, :, 0] * img_width / w\n",
    "    pred_boxes[:, :, :, :, 1] = pred_boxes[:, :, :, :, 1] * img_height / h\n",
    "    pred_boxes[:, :, :, :, 2] = pred_boxes[:, :, :, :, 2]\n",
    "    pred_boxes[:, :, :, :, 3] = pred_boxes[:, :, :, :, 3]\n",
    "\n",
    "    pred_boxes = box_xywh_to_xyxy(pred_boxes)\n",
    "    pred_boxes = np.tile(np.expand_dims(pred_boxes, axis=4), (1, 1, 1, 1, class_num, 1))\n",
    "    pred_labels = np.zeros_like(pred_scores) + np.arange(class_num)\n",
    "\n",
    "    return pred_boxes.reshape((n, -1, 4)), pred_scores.reshape((n, -1)), pred_labels.reshape((n, -1))\n",
    "\n",
    "\n",
    "def get_all_yolo_pred(outputs, yolo_anchors, yolo_classes, input_shape):\n",
    "    all_pred_boxes = []\n",
    "    all_pred_scores = []\n",
    "    all_pred_labels = []\n",
    "    for output, anchors, classes in zip(outputs, yolo_anchors, yolo_classes):\n",
    "        pred_boxes, pred_scores, pred_labels = get_yolo_detection(output, anchors, classes, input_shape[0], input_shape[1])\n",
    "        all_pred_boxes.append(pred_boxes)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "        all_pred_scores.append(pred_scores)\n",
    "    pred_boxes = np.concatenate(all_pred_boxes, axis=1)\n",
    "    pred_scores = np.concatenate(all_pred_scores, axis=1)\n",
    "    pred_labels = np.concatenate(all_pred_labels, axis=1)\n",
    "\n",
    "    return pred_boxes, pred_scores, pred_labels\n",
    "\n",
    "\n",
    "def calc_nms_box(pred_boxes, pred_scores, pred_labels, valid_thresh=0.4, nms_thresh=0.45, nms_topk=400):\n",
    "    output_boxes = np.empty((0, 4))\n",
    "    output_scores = np.empty(0)\n",
    "    output_labels = np.empty(0)\n",
    "    for boxes, labels, scores in zip(pred_boxes, pred_labels, pred_scores):\n",
    "        valid_mask = scores > valid_thresh\n",
    "        boxes = boxes[valid_mask]\n",
    "        scores = scores[valid_mask]\n",
    "        labels = labels[valid_mask]\n",
    "\n",
    "        score_sort_index = np.argsort(scores)[::-1]\n",
    "        boxes = boxes[score_sort_index][:nms_topk]\n",
    "        scores = scores[score_sort_index][:nms_topk]\n",
    "        labels = labels[score_sort_index][:nms_topk]\n",
    "\n",
    "        for c in np.unique(labels):\n",
    "            c_mask = labels == c\n",
    "            c_boxes = boxes[c_mask]\n",
    "            c_scores = scores[c_mask]\n",
    "\n",
    "            detect_boxes = []\n",
    "            detect_scores = []\n",
    "            detect_labels = []\n",
    "            while c_boxes.shape[0]:\n",
    "                detect_boxes.append(c_boxes[0])\n",
    "                detect_scores.append(c_scores[0])\n",
    "                detect_labels.append(c)\n",
    "                if c_boxes.shape[0] == 1:\n",
    "                    break\n",
    "                iou = box_iou_xyxy(detect_boxes[-1].reshape((1, 4)), c_boxes[1:])\n",
    "                c_boxes = c_boxes[1:][iou < nms_thresh]\n",
    "                c_scores = c_scores[1:][iou < nms_thresh]\n",
    "\n",
    "            output_boxes = np.append(output_boxes, detect_boxes, axis=0)\n",
    "            output_scores = np.append(output_scores, detect_scores)\n",
    "            output_labels = np.append(output_labels, detect_labels)\n",
    "    return output_boxes, output_scores, output_labels\n",
    "\n",
    "\n",
    "def infer(image_path):\n",
    "    \"\"\"\n",
    "    预测，将结果保存到一副新的图片中\n",
    "    :param image_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin, tensor_img, resized_img = read_image(image_path)\n",
    "    t1 = time.time()\n",
    "    batch_outputs = exe.run(inference_program,\n",
    "                        feed={feed_target_names[0]: tensor_img},\n",
    "                        fetch_list=fetch_targets)\n",
    "    period = time.time() - t1\n",
    "    print(\"predict cost time:{0}\".format(\"%2.2f sec\" % period))\n",
    "    input_w, input_h = origin.size[0], origin.size[1]\n",
    "    yolo_anchors, yolo_classes = get_yolo_anchors_classes(class_dim, anchors, anchor_mask)\n",
    "    pred_boxes, pred_scores, pred_labels = get_all_yolo_pred(batch_outputs, yolo_anchors, yolo_classes, (target_size[1], target_size[2]))\n",
    "    boxes, scores, labels = calc_nms_box(pred_boxes, pred_scores, pred_labels, valid_thresh, nms_threshold)\n",
    "    boxes = rescale_box_in_input_image(boxes, [input_h, input_w], target_size[1])\n",
    "    print(\"result boxes: \", boxes)\n",
    "    print(\"result scores:\", scores)\n",
    "    print(\"result labels:\", labels)\n",
    "    last_dot_index = image_path.rfind('.')\n",
    "    out_path = image_path[:last_dot_index]\n",
    "    out_path += '-reslut.jpg'\n",
    "    draw_bbox_image(origin, boxes, labels, out_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # image_path = sys.argv[1]\n",
    "    name_list = os.listdir('data/data7085/test/images/')\n",
    "    for name_ in name_list:\n",
    "        image_path = os.path.join('data/data7085/test/images', name_)\n",
    "        infer(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
